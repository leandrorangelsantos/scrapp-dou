{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "########                                                  ########\n",
    "########   Caderno Jupyter para fazer scrapp              ########\n",
    "########   do diario oficial, e outros                    ########\n",
    "########                                                  ########\n",
    "########                                                  ########\n",
    "##################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas necessarias\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "import json\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.image import MIMEImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metodo para enviar email\n",
    "\n",
    "def enviarEmail(assunto, mensagem, destinatario):\n",
    "    mailserver = smtplib.SMTP('smtp.df.cgu',25)\n",
    "    mailserver.ehlo()\n",
    "    mailserver.login('leandrors', 'padrao@2009')\n",
    "    mailserver.sendmail('leandro.rangel@cgu.gov.br',destinatario,mensagem.as_string())\n",
    "    mailserver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# parametros para o envio do email\n",
    "subject = \"BeTanIA - Leitura de DOU\"\n",
    "emailFrom = \"leandro.rangel@cgu.gov.br\"\n",
    "emailTo = \"leandro.rangel@cgu.gov.br\"\n",
    "\n",
    "\n",
    "htmlSessao1 = \"\"\n",
    "htmlSessao2 = \"\"\n",
    "htmlSessao3 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definicao das URLs\n",
    "\n",
    "hoje = date.today()\n",
    "hojeFormatado = hoje.strftime('%d-%m-%Y')\n",
    "\n",
    "urlSessao1 = \"http://www.in.gov.br/leiturajornal?data=\"+hojeFormatado+\"&secao=do1\"\n",
    "#urlSessao1 = \"http://www.in.gov.br/leiturajornal?data=15-07-2019&secao=do1\"\n",
    "urlInterno = \"http://www.in.gov.br/web/dou/-/\"\n",
    "\n",
    "urlSessao2 = \"http://www.in.gov.br/leiturajornal?data=\"+hojeFormatado+\"&secao=do2\"\n",
    "\n",
    "urlSessao3 = \"http://www.in.gov.br/leiturajornal?data=\"+hojeFormatado+\"&secao=do3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessao 1\n",
    "# com base na URL , fazemos a requsição e obtemos o JSON\n",
    "response_sessao1 = requests.get(urlSessao1)\n",
    "soup_sessao1 = BeautifulSoup(response_sessao1.text, \"html.parser\")\n",
    "element_sessao1 = soup_sessao1.find(\"script\", {\"type\":\"application/json\"})\n",
    "json_sessao1 = json.loads(element_sessao1.text)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## com base nos dados crus da sessao, vemos se tem conteúdo da CGU\n",
    "## encontrando , adicionamos na lista de resposta\n",
    "htmlSessao1+=\"<b>Seção 1.</b><br>\"\n",
    "urlsSessao1 = []\n",
    "urlsSessao1INSS = []\n",
    "for elemento in json_sessao1['jsonArray']:\n",
    "    if \"Controladoria\" in elemento['hierarchyStr']:\n",
    "        urlsSessao1.append(elemento['urlTitle'])\n",
    "    if \"Instituto Nacional do Seguro Social\" in elemento['hierarchyStr']:\n",
    "        urlsSessao1INSS.append(elemento['urlTitle'])\n",
    "        \n",
    "if len(urlsSessao1)>0:\n",
    "    for title in urlsSessao1:\n",
    "        htmlSessao1+=\"<b>CGU</b><br>\"\n",
    "        response_Interno1 = requests.get(urlInterno+title)\n",
    "        soup_Interno1 = BeautifulSoup(response_Interno1.text, \"html.parser\")        \n",
    "        identifica = soup_Interno1.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao1+=\"<b>\"+identifica[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno1.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao1+=i.text+\"<br>\"\n",
    "        htmlSessao1+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao1+=\"Não foi encontrada publicações da CGU na seção 1<br><br>\"\n",
    "\n",
    "if len(urlsSessao1INSS)>0:\n",
    "    for title in urlsSessao1INSS:\n",
    "        htmlSessao1+=\"<b>INSS</b><br>\"\n",
    "        response_Interno1 = requests.get(urlInterno+title)\n",
    "        soup_Interno1 = BeautifulSoup(response_Interno1.text, \"html.parser\")        \n",
    "        identifica = soup_Interno1.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao1+=\"<b>\"+identifica[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno1.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao1+=i.text+\"<br>\"\n",
    "        htmlSessao1+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao1+=\"Não foi encontrada publicações do INSS na seção 1<br><br>\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sessao 2 \n",
    "# com base na URL , fazemos a requsição e obtemos o JSON\n",
    "response_sessao2 = requests.get(urlSessao2)\n",
    "soup_sessao2 = BeautifulSoup(response_sessao2.text, \"html.parser\")\n",
    "element_sessao2 = soup_sessao2.find(\"script\", {\"type\":\"application/json\"})\n",
    "json_sessao2 = json.loads(element_sessao2.text)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## com base nos dados crus da sessao, vemos se tem conteúdo da CGU\n",
    "## encontrando , adicionamos na lista de resposta\n",
    "htmlSessao2+=\"<b>Seção 2.</b><br>\"\n",
    "urlsSessao2 = []\n",
    "urlsSessao2INSS = []\n",
    "\n",
    "for elemento in json_sessao2['jsonArray']:\n",
    "    if \"Controladoria\" in elemento['hierarchyStr']:\n",
    "        urlsSessao2.append(elemento['urlTitle'])\n",
    "    if \"Instituto Nacional do Seguro Social\" in elemento['hierarchyStr']:\n",
    "        urlsSessao2INSS.append(elemento['urlTitle'])\n",
    "          \n",
    "if len(urlsSessao2)>0:\n",
    "    for title in urlsSessao2:\n",
    "        htmlSessao2+=\"<b>CGU</b><br>\"\n",
    "        response_Interno2 = requests.get(urlInterno+title)\n",
    "        soup_Interno2 = BeautifulSoup(response_Interno2.text, \"html.parser\")        \n",
    "        identifica2 = soup_Interno2.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao2+=\"<b>\"+identifica2[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno2.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao2+=i.text+\"<br>\"\n",
    "        htmlSessao2+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao2+=\"Não foi encontrada publicações da CGU na seção 2<br><br>\"\n",
    "\n",
    "    \n",
    "if len(urlsSessao2INSS)>0:\n",
    "    for title in urlsSessao2INSS:\n",
    "        htmlSessao2+=\"<b>INSS</b><br>\"\n",
    "        response_Interno2 = requests.get(urlInterno+title)\n",
    "        soup_Interno2 = BeautifulSoup(response_Interno2.text, \"html.parser\")        \n",
    "        identifica2 = soup_Interno2.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao2+=\"<b>\"+identifica2[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno2.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao2+=i.text+\"<br>\"\n",
    "        htmlSessao2+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao2+=\"Não foi encontrada publicações do INSS na seção 2<br><br>\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sessao 3 \n",
    "# com base na URL , fazemos a requsição e obtemos o JSON\n",
    "response_sessao3 = requests.get(urlSessao3)\n",
    "soup_sessao3 = BeautifulSoup(response_sessao3.text, \"html.parser\")\n",
    "element_sessao3 = soup_sessao3.find(\"script\", {\"type\":\"application/json\"})\n",
    "json_sessao3 = json.loads(element_sessao3.text)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## com base nos dados crus da sessao, vemos se tem conteúdo da CGU\n",
    "## encontrando , adicionamos na lista de resposta\n",
    "htmlSessao3+=\"<b>Seção 3.</b><br>\"\n",
    "urlsSessao3 = []\n",
    "urlsSessao3INSS = []\n",
    "for elemento in json_sessao3['jsonArray']:\n",
    "    if \"Controladoria\" in elemento['hierarchyStr']:\n",
    "        urlsSessao3.append(elemento['urlTitle'])\n",
    "    if \"Instituto Nacional do Seguro Social\" in elemento['hierarchyStr']:\n",
    "        urlsSessao3INSS.append(elemento['urlTitle'])\n",
    "           \n",
    "if len(urlsSessao3)>0:\n",
    "    for title in urlsSessao3:\n",
    "        htmlSessao3+=\"<b>CGU</b><br>\"\n",
    "        response_Interno3 = requests.get(urlInterno+title)\n",
    "        soup_Interno3 = BeautifulSoup(response_Interno3.text, \"html.parser\")        \n",
    "        identifica3 = soup_Interno3.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao3+=\"<b>\"+identifica3[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno3.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao3+=i.text+\"<br>\"\n",
    "        htmlSessao3+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao3+=\"Não foi encontrada publicações da CGU na seção 3<br><br>\"\n",
    "\n",
    "if len(urlsSessao3INSS)>0:\n",
    "    for title in urlsSessao3INSS:\n",
    "        htmlSessao3+=\"<b>INSS</b><br>\"\n",
    "        response_Interno3 = requests.get(urlInterno+title)\n",
    "        soup_Interno3 = BeautifulSoup(response_Interno3.text, \"html.parser\")        \n",
    "        identifica3 = soup_Interno3.find_all('p', {\"class\":\"identifica\"})    \n",
    "        htmlSessao3+=\"<b>\"+identifica3[0].text+\"</b><br>\"\n",
    "        paragrafo = soup_Interno3.find_all('p', {\"class\":\"dou-paragraph\"})    \n",
    "        for i in paragrafo:\n",
    "            htmlSessao3+=i.text+\"<br>\"\n",
    "        htmlSessao3+=\"<br>\"\n",
    "else:\n",
    "    htmlSessao3+=\"Não foi encontrada publicações do INSS na seção 3<br><br>\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = MIMEMultipart(\"corpo\")\n",
    "\n",
    "msg['Subject'] = subject\n",
    "msg['From'] = emailFrom\n",
    "msg['To'] = emailTo\n",
    "\n",
    "corpoHTML = MIMEText(htmlSessao1+htmlSessao2+htmlSessao3, 'html')\n",
    "\n",
    "msg.attach(corpoHTML)\n",
    "\n",
    "enviarEmail(\"DOU\",msg,'leandro.rangel@cgu.gov.br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
